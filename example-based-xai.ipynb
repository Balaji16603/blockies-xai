{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balaji16603/blockies-xai/blob/main/example-based-xai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSsAbtwND7K_"
      },
      "source": [
        "# Blockies Dataset\n",
        "\n",
        "This notebook download the blockies dataset and the corresponding trained model.  This is then used to evaluate the model on all datasets.  \n",
        "\n",
        "Additionally, we provide a review of the various Blocky traits, to review the distributions between ill and healthy Blockies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yi0pAex6RNDU"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import tarfile\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms as T\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import shap\n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SLpJb-H9pxs_"
      },
      "outputs": [],
      "source": [
        "CLASSES = ['Healthy', 'OCDegen']\n",
        "\n",
        "modeltype = 'mobilenet'\n",
        "\n",
        "ds = 'sick_ones_bendbias_v3_2class_normal'\n",
        "eval_ds = 'sick_ones_bendbias_v3_2class_variation'\n",
        "\n",
        "random_state = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua-n5ADsde6b"
      },
      "source": [
        "# Setup and Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HPi0wvbicrct"
      },
      "outputs": [],
      "source": [
        "# data downloading and dataset utilities\n",
        "\n",
        "def download_file(url, file_name, cache_dir=\"data\", extract=True, force_download=False, archive_folder=None):\n",
        "    # Ensure the cache directory exists\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    file_path = os.path.join(cache_dir, file_name)\n",
        "\n",
        "    # Download the file\n",
        "    if not os.path.exists(file_path) or force_download:\n",
        "      torch.hub.download_url_to_file(url, file_path)\n",
        "      print(f\"File downloaded to: {file_path}\")\n",
        "    else:\n",
        "      print(f\"File already exists at: {file_path}\")\n",
        "\n",
        "    if extract:\n",
        "      with tarfile.open(file_path, \"r:gz\") as tar:\n",
        "          tar.extractall(path=cache_dir)\n",
        "      print(f\"File extracted to: {cache_dir}\")\n",
        "      return Path(cache_dir) / archive_folder if archive_folder is not None else Path(cache_dir)\n",
        "\n",
        "    return Path(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QsVe_sgNxdPk"
      },
      "outputs": [],
      "source": [
        "def load_dataframe(data_dir, dataset):\n",
        "  data_dir = data_dir / dataset\n",
        "  df = pd.read_json(data_dir / 'parameters.jsonl', lines=True)\n",
        "  df['filename'] = df['id'] + '.png'\n",
        "  df['ill'] = df['ill'].astype(int).astype(str)\n",
        "  return df\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, data_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.data_dir, self.df.iloc[idx]['filename'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = int(self.df.iloc[idx]['ill'])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReNR_Y0QProQ"
      },
      "source": [
        "## Load Dataset and Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a1B47gWYgVG",
        "outputId": "e64208fe-fff4-4c22-f186-7ae0264a40e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.00G/1.00G [00:29<00:00, 36.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded to: data/blockies_datasets.tar.gz\n"
          ]
        }
      ],
      "source": [
        "# download data direcly from sciebo\n",
        "# (or setup own data location if prefered)\n",
        "\n",
        "data_dir = download_file(url=\"https://osf.io/download/kexzt/?view_only=adcc520b88cc4ea3b8236c5178ba3ab5\",\n",
        "                         file_name=\"blockies_datasets.tar.gz\",\n",
        "                         cache_dir='data', # change this if not using Colab\n",
        "                         extract=True,\n",
        "                         force_download=False,\n",
        "                         archive_folder='blockies_datasets')\n",
        "data_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn3D8znPQN-F"
      },
      "outputs": [],
      "source": [
        "ds_dir = data_dir / ds\n",
        "eval_ds_dir = data_dir / eval_ds\n",
        "ds_dir, eval_ds_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-yCAoLQprGc"
      },
      "outputs": [],
      "source": [
        "# 2 class dataset\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# 2 class dataset\n",
        "mean = np.array([0.8068, 0.7830, 0.8005])\n",
        "std  = np.array([0.1093, 0.1136, 0.1029])\n",
        "\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=mean, std=std)\n",
        "  ])\n",
        "\n",
        "# Load the DataFrames using the load_dataframe function\n",
        "train_df = load_dataframe(ds_dir, 'train')\n",
        "val_df = load_dataframe(ds_dir, 'validation')\n",
        "test_df = load_dataframe(ds_dir, 'test')\n",
        "eval_df = load_dataframe(eval_ds_dir, 'test')\n",
        "xai_df = pd.read_csv('xai_samples_df.csv')\n",
        "\n",
        "print(len(train_df), len(val_df), len(test_df), len(eval_df), len(xai_df))\n",
        "\n",
        "\n",
        "test_dataset = ImageDataset(test_df,  ds_dir / 'test', transform=transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False,\n",
        "                             num_workers=0, pin_memory=True)\n",
        "\n",
        "eval_dataset = ImageDataset(eval_df,  eval_ds_dir / 'test', transform=transform)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=1, shuffle=False,\n",
        "                             num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "xai_dataset = ImageDataset(xai_df,  eval_ds_dir / 'test', transform=transform)\n",
        "xai_dataloader = DataLoader(xai_dataset, batch_size=1, shuffle=False,\n",
        "                             num_workers=0, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiMdu2w_dj2O"
      },
      "source": [
        "# Model Loading and Evaluation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH-LE1Vlspbt"
      },
      "outputs": [],
      "source": [
        "def load_mobilenetv2(num_classes, pretrained=True, checkpoint_path=None):\n",
        "  \"\"\"Loads a MobileNetV2 model, optionally loading from a checkpoint.\n",
        "\n",
        "  Args:\n",
        "    num_classes: The number of output classes.\n",
        "    pretrained: Whether to load the pre-trained weights.\n",
        "    checkpoint_path: Path to a checkpoint file to load.\n",
        "\n",
        "  Returns:\n",
        "    A MobileNetV2 model.\n",
        "  \"\"\"\n",
        "  model = models.mobilenet_v2(weights=None if not pretrained else 'DEFAULT')\n",
        "  model.classifier[1] = nn.Linear(model.last_channel, num_classes)\n",
        "\n",
        "  if checkpoint_path:\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
        "    if isinstance(checkpoint, dict) and \"state_dict\" in checkpoint:\n",
        "            model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
        "    else:\n",
        "            model.load_state_dict(checkpoint, strict=False)\n",
        "    print(f\"Loaded checkpoint from: {checkpoint_path}\")\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd7Ww-9otfaV"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "  \"\"\"\n",
        "  Sets random seeds for reproducibility.\n",
        "  \"\"\"\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    preds = []\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Track loss and accuracy\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            preds.extend(predicted.cpu().numpy())\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f\"Evaluation Loss: {avg_loss:.4f}, Evaluation Accuracy: {accuracy:.4f}\")\n",
        "    return avg_loss, accuracy, np.array(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33bS-lo5bxD9"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = download_file(url='https://osf.io/download/5crqh/?view_only=adcc520b88cc4ea3b8236c5178ba3ab5',\n",
        "                                file_name='best_model.pth',\n",
        "                                cache_dir='checkpoint/mobilenetv2_checkpoint', # change this if not using Colab\n",
        "                                extract=False,\n",
        "                                force_download=False)\n",
        "checkpoint_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7ViedtsuqzK"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-gxat5Ju4zD"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMt9eHzsYrMy"
      },
      "outputs": [],
      "source": [
        "# load best model and evaluate\n",
        "model = load_mobilenetv2(num_classes=len(CLASSES),\n",
        "                         pretrained=False,\n",
        "                         checkpoint_path=checkpoint_path)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "_, _, test_preds = evaluate_model(model, test_dataloader, criterion, device)\n",
        "_, _, eval_preds = evaluate_model(model, eval_dataloader, criterion, device)\n",
        "_, _, xai_preds = evaluate_model(model, xai_dataloader, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtr84c-WYrMy"
      },
      "outputs": [],
      "source": [
        "test_df['pred'] = test_preds\n",
        "eval_df['pred'] = eval_preds\n",
        "xai_df['pred'] = xai_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbTjUiRlYrMy"
      },
      "source": [
        "## View the XAI Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apP6nCVpYrMy"
      },
      "outputs": [],
      "source": [
        "def display_images(df, n_rows, n_cols, img_dir, title, random_state=0):\n",
        "  \"\"\" Function to display images in a grid randomly selected from a dataframe of images.\n",
        "\n",
        "  Args:\n",
        "    df (pd.DataFrame): dataframe of images\n",
        "    n_rows (int): number of rows in the grid\n",
        "    n_cols (int): number of columns in the grid\n",
        "    title (str): title of the plot\n",
        "    random_state (int): random state for reproducibility\n",
        "  \"\"\"\n",
        "\n",
        "  if n_rows == 0 and n_cols == 0:\n",
        "    print(f'Not data to display for Figure - {title}')\n",
        "    return\n",
        "\n",
        "  if n_rows * n_cols < len(df):\n",
        "    df = df.sample(n_rows * n_cols, random_state=random_state)\n",
        "\n",
        "  figsize = (n_cols * 2, n_rows*2.5)\n",
        "  print(figsize)\n",
        "\n",
        "  test_images = np.array([Image.open(p).convert('RGB') for p in img_dir / df['filename']]) * 1. / 255\n",
        "  fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
        "  axes = np.array(axes)\n",
        "  for i, (ax, idx) in enumerate(zip(axes.flat, df.index)):\n",
        "    ax.imshow(test_images[i])\n",
        "    ax.set_title(f'True={df.loc[idx][\"ill\"]} - Pred={df.loc[idx][\"pred\"]}')\n",
        "    ax.axis('off')\n",
        "\n",
        "  fig.suptitle(title)\n",
        "  fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSQisw7nYrMy"
      },
      "outputs": [],
      "source": [
        "display_images(xai_df, 5, 8, eval_ds_dir / 'test', f'XAI Dataset', random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyfsMDUvYrMz"
      },
      "source": [
        "## Generate Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSmHbrvPYrM0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def compute_feature_distances(target_features, dataset_features):\n",
        "    \"\"\"\n",
        "    Compute distances between target features and all dataset examples.\n",
        "    \"\"\"\n",
        "    distances = euclidean_distances(target_features.reshape(1, -1), dataset_features)\n",
        "    return distances.flatten()\n",
        "\n",
        "def get_closest_examples(target_features, dataset_df, feature_columns, N=5):\n",
        "    \"\"\"\n",
        "    Find the closest N examples to the target features based on specified columns.\n",
        "    \"\"\"\n",
        "    dataset_features = dataset_df[feature_columns].values\n",
        "    distances = compute_feature_distances(target_features, dataset_features)\n",
        "    dataset_df['distance'] = distances\n",
        "    closest_examples = dataset_df.nsmallest(N, 'distance')\n",
        "    return closest_examples\n",
        "\n",
        "def visualize_examples_with_predictions(target_image_path, target_pred, target_true, closest_examples, data_dir, class_names):\n",
        "    \"\"\"\n",
        "    Visualize the target image, the closest examples, and their predicted classes.\n",
        "\n",
        "    Args:\n",
        "        target_image_path (str): Path to the target image.\n",
        "        closest_examples (DataFrame): DataFrame containing the closest examples.\n",
        "        data_dir (Path): Directory containing the image data.\n",
        "        model (torch.nn.Module): Trained model for prediction.\n",
        "        transform (torchvision.transforms.Compose): Transformations to apply to images.\n",
        "        device (torch.device): Device to use (CPU or GPU).\n",
        "        class_names (list): List of class names corresponding to model outputs.\n",
        "    \"\"\"\n",
        "    # Load the target image\n",
        "    target_image = Image.open(target_image_path).convert('RGB')\n",
        "\n",
        "    # Plot target image\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(1, len(closest_examples) + 1, 1)\n",
        "    plt.imshow(target_image)\n",
        "    plt.title(f\"Target Image\\nPred: {class_names[target_pred]}\\nActual: {class_names[target_true]}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Predict and plot closest examples\n",
        "    for idx, (_, row) in enumerate(closest_examples.iterrows()):  # Fix the index to be sequential\n",
        "        example_image_path = data_dir / row['filename']\n",
        "        example_image = Image.open(example_image_path).convert('RGB')\n",
        "        pred = row['pred']\n",
        "        true_label = int(row['ill'])\n",
        "        predicted_class = class_names[pred]\n",
        "        true_class = class_names[true_label]\n",
        "\n",
        "        # Plot the image with prediction and distance\n",
        "        plt.subplot(1, len(closest_examples) + 1, idx + 2)\n",
        "        plt.imshow(example_image)\n",
        "        plt.title(f\"Dist: {row['distance']:.2f}\\nPred: {predicted_class}\\nTrue: {true_class}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB7BnScwYrM0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Specify feature columns\n",
        "feature_columns = [\n",
        "    'spherical', 'ill_spherical', 'num_diff', 'bending', 'obj_rotation_roll',\n",
        "    # 'obj_rotation_pitch', 'obj_rotation_yaw', 'fliplr',\n",
        "    # 'position_x', 'position_y',\n",
        "    'arm_position', 'obj_color', 'bg_color'\n",
        "]\n",
        "\n",
        "columns = ['PATIENT_ID', 'X_RAY_IMAGE', 'TRUE_DIAG', 'SUGGESTED_DIAG', 'Example1', 'Example2', 'Example3']\n",
        "df = pd.DataFrame(columns=columns)\n",
        "for idx, row in xai_df.iterrows():\n",
        "\n",
        "  # Example usage\n",
        "  target_image_path = str(eval_ds_dir / 'test' / row['filename'])  # Path to target image\n",
        "  target_features = row[feature_columns].values  # Features of target image\n",
        "  target_pred = row['pred']  # Prediction of target image\n",
        "  target_true = row['ill']  # True label of target image\n",
        "  target_true = int(target_true)\n",
        "\n",
        "  # Get closest examples\n",
        "  N = 3  # Number of closest examples to retrieve\n",
        "  id_to_drop = row['id']  # Extract the 'id' column from xai_df\n",
        "  filtered_eval_df = eval_df.loc[eval_df['id'] != id_to_drop].copy()\n",
        "  closest_examples = get_closest_examples(target_features, filtered_eval_df, feature_columns, N)\n",
        "\n",
        "\n",
        "  # dataframe to original image, true adn pred. diagnosis, closest example paths\n",
        "  data = dict(\n",
        "      PATIENT_ID = idx,\n",
        "      X_RAY_IMAGE = row['filename'],\n",
        "      TRUE_DIAG = CLASSES[row['pred']],\n",
        "      SUGGESTED_DIAG = CLASSES[row['ill']],\n",
        "      Example1 = closest_examples['filename'].values[0],\n",
        "      Example2 = closest_examples['filename'].values[1],\n",
        "      Example3 = closest_examples['filename'].values[2]\n",
        "  )\n",
        "\n",
        "  df = pd.concat([df, pd.DataFrame(data, index=[idx])], ignore_index=True)\n",
        "\n",
        "\n",
        "  # # Visualize results\n",
        "  # # Example usage\n",
        "  # visualize_examples_with_predictions(\n",
        "  #     target_image_path=target_image_path,\n",
        "  #     target_pred=target_pred,\n",
        "  #     target_true=target_true,\n",
        "  #     closest_examples=closest_examples,\n",
        "  #     data_dir=eval_ds_dir / 'test',\n",
        "  #     class_names=CLASSES\n",
        "  # )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9BrNGAYYrM1"
      },
      "outputs": [],
      "source": [
        "# TODO: Code do save example files and data into CSV file compatible with website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAJBOmH4YrM1"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CAsMQc0YrM1"
      },
      "outputs": [],
      "source": [
        "filecols = ['X_RAY_IMAGE', 'Example1', 'Example2', 'Example3']\n",
        "unique_files = df[filecols].values.flatten()\n",
        "unique_files = np.unique(unique_files)\n",
        "\n",
        "# zip and download these files and add to 'images' folder for the website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ICegOMJYrM1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}